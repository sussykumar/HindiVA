import pyaudio
import json
import datetime
from vosk import Model, KaldiRecognizer
import requests

from intentparser import parse_multiple_intents
from speaker import speak_hindi

import datetime # Make sure this is at the top of main.py!

def generate_response(intent):
    """Maps the detected intent to a spoken Hindi response."""
    now = datetime.datetime.now()
    
    # --- Home Automation ---
    if intent == "LIGHT_ON":
        return "‡§†‡•Ä‡§ï ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§¨‡§§‡•ç‡§§‡•Ä ‡§ö‡§æ‡§≤‡•Ç ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Å‡•§" 
        
    elif intent == "LIGHT_OFF":
        return "‡§†‡•Ä‡§ï ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§¨‡§§‡•ç‡§§‡•Ä ‡§¨‡§Ç‡§¶ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Å‡•§" 
        
    elif intent == "FAN_ON":
        return "‡§†‡•Ä‡§ï ‡§π‡•à, ‡§Æ‡•à‡§Ç‡§®‡•á ‡§™‡§Ç‡§ñ‡§æ ‡§ö‡§æ‡§≤‡•Ç ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à‡•§" 
        
    elif intent == "FAN_OFF":
        return "‡§†‡•Ä‡§ï ‡§π‡•à, ‡§™‡§Ç‡§ñ‡§æ ‡§¨‡§Ç‡§¶ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§" 
        
    elif intent == "AC_ON":
        return "‡§†‡•Ä‡§ï ‡§π‡•à, ‡§è‡§∏‡•Ä ‡§ö‡§æ‡§≤‡•Ç ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§"
        
    # --- Time and Date ---
    elif intent == "TIME_ASK":
        hour = now.hour % 12 or 12
        return f"‡§Ö‡§≠‡•Ä ‡§∏‡§Æ‡§Ø {hour} ‡§¨‡§ú‡§ï‡§∞ {now.minute} ‡§Æ‡§ø‡§®‡§ü ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à‡•§"
        
    elif intent == "DATE_ASK":
        return f"‡§Ü‡§ú {now.day} ‡§§‡§æ‡§∞‡•Ä‡§ñ ‡§π‡•à‡•§" 
        
    elif intent == "DAY_ASK":
        hindi_days = ["‡§∏‡•ã‡§Æ‡§µ‡§æ‡§∞", "‡§Æ‡§Ç‡§ó‡§≤‡§µ‡§æ‡§∞", "‡§¨‡•Å‡§ß‡§µ‡§æ‡§∞", "‡§¨‡•É‡§π‡§∏‡•ç‡§™‡§§‡§ø‡§µ‡§æ‡§∞", "‡§∂‡•Å‡§ï‡•ç‡§∞‡§µ‡§æ‡§∞", "‡§∂‡§®‡§ø‡§µ‡§æ‡§∞", "‡§∞‡§µ‡§ø‡§µ‡§æ‡§∞"]
        today_hindi = hindi_days[now.weekday()]
        return f"‡§Ü‡§ú {today_hindi} ‡§π‡•à‡•§"
        
    # --- Temperature and Weather (Offline Mock Data) ---
    elif intent == "WEATHER_ASK" or intent == "TEMP_ASK":
        return "‡§ï‡§Æ‡§∞‡•á ‡§ï‡§æ ‡§§‡§æ‡§™‡§Æ‡§æ‡§® ‡§™‡§ö‡•ç‡§ö‡•Ä‡§∏ ‡§°‡§ø‡§ó‡•ç‡§∞‡•Ä ‡§π‡•à, ‡§î‡§∞ ‡§Æ‡•å‡§∏‡§Æ ‡§∏‡§æ‡§´‡§º ‡§π‡•à‡•§" 
        
    elif intent == "RAIN_ASK":
        return "‡§Ö‡§≠‡•Ä ‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§∏‡§Ç‡§≠‡§æ‡§µ‡§®‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§"
        
    # --- Reminders and Alarms ---
    elif intent == "ALARM_SET":
        return "‡§Ö‡§≤‡§æ‡§∞‡•ç‡§Æ ‡§∏‡•á‡§ü ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§"
        
    elif intent == "REMINDER_SET":
        return "‡§†‡•Ä‡§ï ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§Ø‡§æ‡§¶ ‡§¶‡§ø‡§≤‡§æ ‡§¶‡•Ç‡§Å‡§ó‡•Ä‡•§"
        
    elif intent == "ALARM_STOP":
        return "‡§Ö‡§≤‡§æ‡§∞‡•ç‡§Æ ‡§¨‡§Ç‡§¶ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§"
        
    # --- Translation ---
    elif intent == "TRANSLATE_ASK":
        return "‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•á‡§∞‡§æ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Ö‡§≠‡•Ä ‡§ë‡§´‡§º‡§≤‡§æ‡§á‡§® ‡§π‡•à‡•§"
        
    # --- Fallbacks ---
    elif intent == "UNKNOWN_COMMAND":
        return "‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•Å‡§ù‡•á ‡§∏‡§Æ‡§ù ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§Ø‡§æ‡•§"
        
    else:
        # Developer fallback for missing intents
        return "‡§Æ‡•à‡§Ç‡§®‡•á ‡§ï‡§Æ‡§æ‡§Ç‡§° ‡§∏‡§Æ‡§ù ‡§≤‡§ø‡§Ø‡§æ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§§‡§æ‡•§"
def ask_ollama_translator(text_to_translate):
    """Uses Qwen 3B purely for linguistic translation."""
    url = "http://localhost:11434/api/generate"
    
    # We force the LLM to act ONLY as a translator, outputting pure Hindi
    system_prompt = "You are an expert offline language translator. Translate the user's input into natural, conversational Hindi. Output ONLY the Hindi translation. Do not explain anything."
    
    payload = {
        "model": "qwen2.5:3b", # The intelligent linguistic model
        "prompt": f"{system_prompt}\nUser: {text_to_translate}",
        "stream": False
    }
    
    try:
        # 60-second timeout to give the 3B model time to boot into the GPU
        response = requests.post(url, json=payload, timeout=60)
        if response.status_code == 200:
            return response.json()['response']
        else:
            return "‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•á‡§∞‡•á ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§ñ‡§∞‡§æ‡§¨‡•Ä ‡§π‡•à‡•§"
    except requests.exceptions.ConnectionError:
        return "‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•á‡§∞‡§æ ‡§≤‡•ã‡§ï‡§≤ ‡§∏‡§∞‡•ç‡§µ‡§∞ ‡§Ö‡§≠‡•Ä ‡§¨‡§Ç‡§¶ ‡§π‡•à‡•§"
    except requests.exceptions.ReadTimeout:
        return "‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§∏‡§Æ‡§Ø ‡§≤‡§ó ‡§∞‡§π‡§æ ‡§π‡•à‡•§"
# ==========================================
# 1. INITIALIZE ALL AI MODELS
# ==========================================
print("Loading Vosk Acoustic Model (Ears)...")
model = Model("model")

# THE UPGRADE: Two Recognizers sharing the same brain
# 1. The Bouncer: Only knows how to listen for the wake word
wake_word_grammar = '["‡§®‡§Æ‡§∏‡•ç‡§§‡•á", "‡§∏‡•Å‡§®‡•ã", "[unk]"]'
wake_recognizer = KaldiRecognizer(model, 16000, wake_word_grammar)

# 2. The Command Listener: Knows the whole Hindi dictionary
main_recognizer = KaldiRecognizer(model, 16000)

print("Loading Intent Parser (Brain)... Done.")
print("Loading Piper TTS Engine (Voice)... Done.")

audio = pyaudio.PyAudio()
stream = audio.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8000)

print("\n" + "="*50)
print("üü¢ SOVEREIGN SENTRY: ONLINE & AIR-GAPPED")
print("Say 'Namaste' or 'Suno' to wake me up.")
print("Press Ctrl+C to shut down.")
print("="*50 + "\n")

# State tracking
is_awake = False

try:
    while True:
        data = stream.read(4000, exception_on_overflow=False)
        
        # ==========================================
        # STATE 1: SLEEPING (Listening for Wake Word)
        # ==========================================
        if not is_awake:
            if wake_recognizer.AcceptWaveform(data):
                result = json.loads(wake_recognizer.Result())
                text = result.get('text', '')
                
                if "‡§®‡§Æ‡§∏‡•ç‡§§‡•á" in text or "‡§∏‡•Å‡§®‡•ã" in text:
                    print("\nüîî [Wake Word Detected]: Waking up system...")
                    speak_hindi("‡§π‡§æ‡§Å ‡§ï‡•ç‡§µ‡§æ‡§∞‡•ç‡§ï, ‡§¨‡§§‡§æ‡§á‡§Ø‡•á?") # "Yes Quark, tell me?"
                    
                    # Switch state and flush the audio buffer
                    is_awake = True
                    stream.stop_stream()
                    stream.start_stream()
                    print("Listening for command...")

        # ==========================================
        # STATE 2: AWAKE (Listening for Command)
        # ==========================================
      
        else:
            if main_recognizer.AcceptWaveform(data):
                result = json.loads(main_recognizer.Result())
                transcribed_text = result.get('text', '')
                
                if transcribed_text:
                    print(f"\nüó£Ô∏è [Quark]: {transcribed_text}")
                    
                    intent_list = parse_multiple_intents(transcribed_text)
                    combined_replies = []
                    
                    for intent_data in intent_list:
                        detected_intent = intent_data['intent']
                        phrase = intent_data['phrase']
                        confidence = intent_data['confidence']
                        
                        print(f"üß† [Brain]: Detected '{detected_intent}' from '{phrase}' ({confidence}%)")
                        
                        # 1. THE GARBAGE & HALLUCINATION FILTER
                        if detected_intent == "UNKNOWN_COMMAND":
                            word_count = len(phrase.split())
                            if word_count > 2:
                                # They asked a trivia question. Reject it to prevent LLM hallucinations.
                                print("üõë [Router]: Rejecting trivia to stay in Smart Home/Translator mode.")
                                combined_replies.append("‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•à‡§Ç ‡§ï‡•á‡§µ‡§≤ ‡§ò‡§∞ ‡§ï‡•á ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§ï‡•ã ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•Ç‡§Å ‡§Ø‡§æ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•Ç‡§Å‡•§")
                            else:
                                # It was just static/garbage audio
                                print("üõë [Router]: Discarding garbage audio.")
                                combined_replies.append("‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•Å‡§ù‡•á ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∏‡•Å‡§®‡§æ‡§à ‡§®‡§π‡•Ä‡§Ç ‡§¶‡§ø‡§Ø‡§æ‡•§") 

                        # 2. THE NEW INTELLIGENT TRANSLATOR
                        elif detected_intent == "TRANSLATE_ASK":
                            print("üåê [Router]: Translation request detected. Faking latency with audio cue...")
                            
                            # UX Hack: Buy time while the 3B model loads into the GPU
                            stream.stop_stream()
                            speak_hindi("‡§Æ‡•à‡§Ç ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Å...") # "I am translating..."
                            stream.start_stream()
                            
                            print("üß† [LLM]: Qwen 3B is translating...")
                            translated_text = ask_ollama_translator(phrase)
                            combined_replies.append(translated_text)
                            
                        # 3. STANDARD SMART HOME COMMANDS (Lights, Fan, Alarm, Time)
                        else:
                            reply_text = generate_response(detected_intent)
                            combined_replies.append(reply_text)
                            
                    # Combine and speak
                    final_spoken_response = " ".join(combined_replies)
                    print(f"ü§ñ [Assistant]: {final_spoken_response}")
                    
                    if final_spoken_response.strip(): # Only speak if there is actual text
                        stream.stop_stream()
                        speak_hindi(final_spoken_response)
                        stream.start_stream()
                    
                    print("\nüí§ Going back to sleep...")
                    is_awake = False
                    
            else:
                partial = json.loads(main_recognizer.PartialResult())
                if partial.get('partial'):
                    print(f"Processing... {partial['partial']}", end='\r')

except KeyboardInterrupt:
    print("\n\nShutting down system safely...")
    stream.stop_stream()
    stream.close()
    audio.terminate()