import os
import sys
import json
import pyaudio
import subprocess
import datetime
import threading
import re
from vosk import Model, KaldiRecognizer
from intentparser import parse_multiple_intents
import hardware 

# ==========================================
# CONFIGURATION & BLUETOOTH OPTIMIZATION
# ==========================================
VOSK_MODEL_PATH = "model"
PIPER_MODEL = "hi_IN-pratham-medium.onnx"
WAKE_WORDS = ["à¤¸à¥à¤¨à¥‹", "à¤¨à¤®à¤¸à¥à¤¤à¥‡"]

if sys.platform == "win32":
    PIPER_EXE = "piper\\piper.exe"
    PLAY_CMD = "start /wait response.wav"
else:
    PIPER_EXE = "./piper/piper"
    PLAY_CMD = "paplay response.wav" 

# ==========================================
# TEXT-TO-SPEECH (PIPER)
# ==========================================
def speak_hindi(text):
    print(f"âš™ï¸ Synthesizing: '{text}'")
    command = [PIPER_EXE, "-m", PIPER_MODEL, "--output_file", "response.wav"]
    try:
        subprocess.run(
            command, 
            input=text.encode('utf-8'),
            stdout=subprocess.DEVNULL, 
            stderr=subprocess.DEVNULL,
            check=True
        )
        os.system(PLAY_CMD)
        print("âœ… Audio played.\n")
    except subprocess.CalledProcessError:
        print("âŒ Piper TTS Engine failed to synthesize audio.")

# ==========================================
# OFFLINE NLP EXTRACTORS
# ==========================================
def trigger_alarm(message):
    print(f"\nâ° [SYSTEM ALARM]: {message}")
    speak_hindi(message)

def extract_minutes(phrase):
    time_map = {
        "à¤à¤• à¤®à¤¿à¤¨à¤Ÿ": 1, "1 à¤®à¤¿à¤¨à¤Ÿ": 1, "à¤¦à¥‹ à¤®à¤¿à¤¨à¤Ÿ": 2, "2 à¤®à¤¿à¤¨à¤Ÿ": 2, 
        "à¤¤à¥€à¤¨ à¤®à¤¿à¤¨à¤Ÿ": 3, "3 à¤®à¤¿à¤¨à¤Ÿ": 3, "à¤šà¤¾à¤° à¤®à¤¿à¤¨à¤Ÿ": 4, "4 à¤®à¤¿à¤¨à¤Ÿ": 4, 
        "à¤ªà¤¾à¤‚à¤š à¤®à¤¿à¤¨à¤Ÿ": 5, "à¤ªà¤¾à¤à¤š à¤®à¤¿à¤¨à¤Ÿ": 5, "5 à¤®à¤¿à¤¨à¤Ÿ": 5, 
        "à¤¦à¤¸ à¤®à¤¿à¤¨à¤Ÿ": 10, "10 à¤®à¤¿à¤¨à¤Ÿ": 10, "à¤ªà¤‚à¤¦à¥à¤°à¤¹ à¤®à¤¿à¤¨à¤Ÿ": 15, "15 à¤®à¤¿à¤¨à¤Ÿ": 15, 
        "à¤¬à¥€à¤¸ à¤®à¤¿à¤¨à¤Ÿ": 20, "20 à¤®à¤¿à¤¨à¤Ÿ": 20, "à¤¤à¥€à¤¸ à¤®à¤¿à¤¨à¤Ÿ": 30, "30 à¤®à¤¿à¤¨à¤Ÿ": 30, 
        "à¤†à¤§à¤¾ à¤˜à¤‚à¤Ÿà¤¾": 30, "à¤†à¤§à¥‡ à¤˜à¤‚à¤Ÿà¥‡": 30, "à¤à¤• à¤˜à¤‚à¤Ÿà¤¾": 60, "à¤à¤• à¤˜à¤‚à¤Ÿà¥‡": 60
    }
    for key, value in time_map.items():
        if key in phrase:
            return value
    return None

def extract_long_term_event(phrase):
    day = "à¤†à¤œ" 
    if "à¤•à¤²" in phrase: day = "à¤•à¤²"
    elif "à¤ªà¤°à¤¸à¥‹à¤‚" in phrase: day = "à¤ªà¤°à¤¸à¥‹à¤‚"
        
    event = "à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤°"
    if "à¤¬à¤°à¥à¤¥à¤¡à¥‡" in phrase or "à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨" in phrase: event = "à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨"
    elif "à¤®à¥€à¤Ÿà¤¿à¤‚à¤—" in phrase or "à¤¬à¥ˆà¤ à¤•" in phrase: event = "à¤®à¥€à¤Ÿà¤¿à¤‚à¤—"
    elif "à¤µà¥ˆà¤•à¥à¤¸à¥€à¤¨" in phrase or "à¤Ÿà¥€à¤•à¤¾" in phrase or "à¤µà¥ˆà¤•à¥à¤¸à¥€à¤¨à¥‡à¤¶à¤¨" in phrase: event = "à¤µà¥ˆà¤•à¥à¤¸à¥€à¤¨à¥‡à¤¶à¤¨"
    elif "à¤¦à¤µà¤¾à¤ˆ" in phrase: event = "à¤¦à¤µà¤¾à¤ˆ à¤•à¤¾"
        
    if "à¤®à¤¿à¤¨à¤Ÿ" in phrase or "à¤˜à¤‚à¤Ÿà¤¾" in phrase or "à¤˜à¤‚à¤Ÿà¥‡" in phrase:
        return None, None
        
    return event, day

# ==========================================
# 100% OFFLINE RESPONSE GENERATOR
# ==========================================
def generate_response(intent, phrase):
    now = datetime.datetime.now()
    
    # --- Home Automation ---
    if intent == "LIGHT_ON": 
        hardware.control_appliance("LIGHT", "ON")
        return "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¬à¤¤à¥à¤¤à¥€ à¤šà¤¾à¤²à¥‚ à¤•à¤° à¤¦à¥€ à¤—à¤ˆ à¤¹à¥ˆà¥¤" 
    elif intent == "LIGHT_OFF": 
        hardware.control_appliance("LIGHT", "OFF")
        return "à¤ à¥€à¤• à¤¹à¥ˆ, à¤®à¥ˆà¤‚à¤¨à¥‡ à¤¬à¤¤à¥à¤¤à¥€ à¤¬à¤‚à¤¦ à¤•à¤° à¤¦à¥€ à¤¹à¥ˆà¥¤" 
    elif intent == "FAN_ON": 
        hardware.control_appliance("FAN", "ON")
        return "à¤ à¥€à¤• à¤¹à¥ˆ, à¤ªà¤‚à¤–à¤¾ à¤šà¤¾à¤²à¥‚ à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆà¥¤" 
    elif intent == "FAN_OFF": 
        hardware.control_appliance("FAN", "OFF")
        return "à¤ à¥€à¤• à¤¹à¥ˆ, à¤ªà¤‚à¤–à¤¾ à¤¬à¤‚à¤¦ à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆà¥¤" 
    elif intent == "AC_ON": 
        hardware.control_appliance("AC", "ON")
        return "à¤ à¥€à¤• à¤¹à¥ˆ, à¤à¤¸à¥€ à¤šà¤¾à¤²à¥‚ à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆà¥¤"
        
    # --- Time, Date & Weather ---
    elif intent == "TIME_ASK":
        hour = now.hour % 12 or 12
        return f"à¤…à¤­à¥€ à¤¸à¤®à¤¯ {hour} à¤¬à¤œà¤•à¤° {now.minute} à¤®à¤¿à¤¨à¤Ÿ à¤¹à¥‹ à¤°à¤¹à¤¾ à¤¹à¥ˆà¥¤"
    elif intent == "DATE_ASK":
        return f"à¤†à¤œ {now.day} à¤¤à¤¾à¤°à¥€à¤– à¤¹à¥ˆà¥¤" 
    elif intent == "DAY_ASK":
        hindi_days = ["à¤¸à¥‹à¤®à¤µà¤¾à¤°", "à¤®à¤‚à¤—à¤²à¤µà¤¾à¤°", "à¤¬à¥à¤§à¤µà¤¾à¤°", "à¤¬à¥ƒà¤¹à¤¸à¥à¤ªà¤¤à¤¿à¤µà¤¾à¤°", "à¤¶à¥à¤•à¥à¤°à¤µà¤¾à¤°", "à¤¶à¤¨à¤¿à¤µà¤¾à¤°", "à¤°à¤µà¤¿à¤µà¤¾à¤°"]
        return f"à¤†à¤œ {hindi_days[now.weekday()]} à¤¹à¥ˆà¥¤"
    elif intent == "WEATHER_ASK": 
        live_temp = hardware.get_temperature()
        return f"à¤†à¤œ à¤®à¥Œà¤¸à¤® à¤¸à¤¾à¤« à¤¹à¥ˆ à¤”à¤° à¤¤à¤¾à¤ªà¤®à¤¾à¤¨ {live_temp} à¤¡à¤¿à¤—à¥à¤°à¥€ à¤¹à¥ˆà¥¤" 
    elif intent == "TEMP_ASK": 
        live_temp = hardware.get_temperature()
        return f"à¤…à¤­à¥€ à¤•à¤®à¤°à¥‡ à¤•à¤¾ à¤¤à¤¾à¤ªà¤®à¤¾à¤¨ {live_temp} à¤¡à¤¿à¤—à¥à¤°à¥€ à¤¸à¥‡à¤²à¥à¤¸à¤¿à¤¯à¤¸ à¤¹à¥ˆà¥¤"
    elif intent == "RAIN_ASK": 
        return "à¤†à¤œ à¤¬à¤¾à¤°à¤¿à¤¶ à¤•à¥€ à¤•à¥‹à¤ˆ à¤¸à¤‚à¤­à¤¾à¤µà¤¨à¤¾ à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆà¥¤"
        
    # --- Reminders & Alarms ---
    elif intent == "ALARM_SET":
        minutes = extract_minutes(phrase)
        if minutes:
            threading.Timer(minutes * 60, trigger_alarm, args=["à¤†à¤ªà¤•à¤¾ à¤…à¤²à¤¾à¤°à¥à¤® à¤•à¤¾ à¤¸à¤®à¤¯ à¤¹à¥‹ à¤—à¤¯à¤¾ à¤¹à¥ˆà¥¤"]).start()
            return f"à¤ à¥€à¤• à¤¹à¥ˆ, à¤®à¥ˆà¤‚à¤¨à¥‡ {minutes} à¤®à¤¿à¤¨à¤Ÿ à¤•à¤¾ à¤…à¤²à¤¾à¤°à¥à¤® à¤¸à¥‡à¤Ÿ à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤"
        else:
            threading.Timer(60.0, trigger_alarm, args=["à¤…à¤²à¤¾à¤°à¥à¤® à¤•à¤¾ à¤¸à¤®à¤¯ à¤¹à¥‹ à¤—à¤¯à¤¾ à¤¹à¥ˆ!"]).start()
            return "à¤†à¤ªà¤¨à¥‡ à¤¸à¤®à¤¯ à¤¨à¤¹à¥€à¤‚ à¤¬à¤¤à¤¾à¤¯à¤¾, à¤‡à¤¸à¤²à¤¿à¤ à¤®à¥ˆà¤‚à¤¨à¥‡ à¤à¤• à¤®à¤¿à¤¨à¤Ÿ à¤•à¤¾ à¤¡à¥‡à¤®à¥‹ à¤…à¤²à¤¾à¤°à¥à¤® à¤¸à¥‡à¤Ÿ à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤"

    elif intent == "REMINDER_SET":
        event, day = extract_long_term_event(phrase)
        if event and day:
            reminder_data = {"day": day, "event": event, "created_at": str(datetime.datetime.now())}
            with open("offline_database.json", "a", encoding="utf-8") as f:
                f.write(json.dumps(reminder_data, ensure_ascii=False) + "\n")
            return f"à¤ à¥€à¤• à¤¹à¥ˆ, à¤®à¥ˆà¤‚à¤¨à¥‡ {day} à¤•à¥‡ à¤²à¤¿à¤ à¤†à¤ªà¤•à¥‡ {event} à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤•à¥‹ à¤²à¥‹à¤•à¤² à¤¡à¥‡à¤Ÿà¤¾à¤¬à¥‡à¤¸ à¤®à¥‡à¤‚ à¤¸à¥à¤°à¤•à¥à¤·à¤¿à¤¤ à¤•à¤° à¤²à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤"
        else:
            minutes = extract_minutes(phrase)
            if minutes:
                threading.Timer(minutes * 60, trigger_alarm, args=[f"à¤†à¤ªà¤•à¥‡ {minutes} à¤®à¤¿à¤¨à¤Ÿ à¤ªà¥‚à¤°à¥‡ à¤¹à¥‹ à¤—à¤ à¤¹à¥ˆà¤‚à¥¤"]).start()
                return f"à¤ à¥€à¤• à¤¹à¥ˆ, à¤®à¥ˆà¤‚à¤¨à¥‡ {minutes} à¤®à¤¿à¤¨à¤Ÿ à¤•à¤¾ à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤¸à¥‡à¤Ÿ à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤"
            return "à¤®à¥ˆà¤‚à¤¨à¥‡ à¤†à¤ªà¤•à¤¾ à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤¸à¥à¤°à¤•à¥à¤·à¤¿à¤¤ à¤•à¤° à¤²à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤"

    # --- Volume Control (REAL OS Integration) ---
    elif intent == "ALARM_STOP": return "à¤…à¤²à¤¾à¤°à¥à¤® à¤¬à¤‚à¤¦ à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆà¥¤"
    elif intent == "VOLUME_UP": 
        if sys.platform != "win32":
            os.system("pactl set-sink-volume @DEFAULT_SINK@ +15%")
        return "à¤®à¥ˆà¤‚à¤¨à¥‡ à¤†à¤µà¤¾à¤œà¤¼ à¤¬à¤¢à¤¼à¤¾ à¤¦à¥€ à¤¹à¥ˆà¥¤"
    elif intent == "VOLUME_DOWN": 
        if sys.platform != "win32":
            os.system("pactl set-sink-volume @DEFAULT_SINK@ -15%")
        return "à¤®à¥ˆà¤‚à¤¨à¥‡ à¤†à¤µà¤¾à¤œà¤¼ à¤•à¤® à¤•à¤° à¤¦à¥€ à¤¹à¥ˆà¥¤"
        
    # --- Fallbacks ---
    elif intent == "UNKNOWN_COMMAND": return "à¤®à¤¾à¤«à¤¼ à¤•à¥€à¤œà¤¿à¤, à¤®à¥ˆà¤‚ à¤•à¥‡à¤µà¤² à¤˜à¤° à¤•à¥‡ à¤‰à¤ªà¤•à¤°à¤£à¥‹à¤‚ à¤•à¥‹ à¤¨à¤¿à¤¯à¤‚à¤¤à¥à¤°à¤¿à¤¤ à¤•à¤° à¤¸à¤•à¤¤à¥€ à¤¹à¥‚à¤à¥¤"
    else: return "à¤®à¤¾à¤«à¤¼ à¤•à¥€à¤œà¤¿à¤, à¤®à¥à¤à¥‡ à¤¸à¤®à¤ à¤¨à¤¹à¥€à¤‚ à¤†à¤¯à¤¾à¥¤"

# ==========================================
# MAIN AUDIO PIPELINE
# ==========================================
if __name__ == "__main__":
    print("Loading Vosk Acoustic Model (Ears)...")
    if not os.path.exists(VOSK_MODEL_PATH):
        print(f"Error: Vosk model not found at '{VOSK_MODEL_PATH}'.")
        sys.exit(1)
        
    model = Model(VOSK_MODEL_PATH)
    wake_word_grammar = '["à¤¨à¤®à¤¸à¥à¤¤à¥‡", "à¤¸à¥à¤¨à¥‹", "[unk]"]'
    wake_recognizer = KaldiRecognizer(model, 16000, wake_word_grammar)
    main_recognizer = KaldiRecognizer(model, 16000)
    
    audio = pyaudio.PyAudio()
    
    stream = audio.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8000)
    stream.start_stream()

    print("Loading Intent Parser (Brain)... Done.")
    print("Loading Piper TTS Engine (Voice)... Done.\n")
    print("=" * 50)
    print(f"ðŸŸ¢ SOVEREIGN SENTRY: ONLINE & AIR-GAPPED ({sys.platform})")
    print("Say 'Namaste' or 'Suno' to wake me up.")
    print("Press Ctrl+C to shut down.")
    print("=" * 50 + "\n")

    is_awake = False

    try:
        while True:
            data = stream.read(4000, exception_on_overflow=False)

            if not is_awake:
                if wake_recognizer.AcceptWaveform(data):
                    result = json.loads(wake_recognizer.Result())
                    text = result.get('text', '')
                    if any(word in text for word in WAKE_WORDS):
                        print("\nðŸ”” [Wake Word Detected]: Waking up system...")
                        stream.stop_stream()
                        speak_hindi("à¤¹à¤¾à¤ à¤•à¥à¤µà¤¾à¤°à¥à¤•, à¤¬à¤¤à¤¾à¤‡à¤¯à¥‡?") 
                        stream.start_stream()
                        is_awake = True
                        print("Listening for command...")
            else:
                if main_recognizer.AcceptWaveform(data):
                    result = json.loads(main_recognizer.Result())
                    transcribed_text = result.get('text', '')
                    if transcribed_text:
                        print(f"\nðŸ—£ï¸ [Quark]: {transcribed_text}")
                        intent_list = parse_multiple_intents(transcribed_text)
                        combined_replies = []
                        
                        for intent_data in intent_list:
                            detected_intent = intent_data['intent']
                            phrase = intent_data['phrase']
                            confidence = intent_data['confidence']
                            
                            print(f"ðŸ§  [Brain]: Detected '{detected_intent}' from '{phrase}' ({confidence}%)")
                            
                            reply_text = generate_response(detected_intent, phrase)
                            
                            if detected_intent == "UNKNOWN_COMMAND" and len(intent_list) > 1: continue
                            combined_replies.append(reply_text)
                                
                        final_spoken_response = " ".join(combined_replies)
                        print(f"ðŸ¤– [Assistant]: {final_spoken_response}")
                        
                        if final_spoken_response.strip():
                            stream.stop_stream()
                            speak_hindi(final_spoken_response)
                            stream.start_stream()
                        
                        print("\nðŸ’¤ Going back to sleep...")
                        is_awake = False
                        
                else:
                    partial = json.loads(main_recognizer.PartialResult())
                    if partial.get('partial'):
                        print(f"Processing... {partial['partial']}", end='\r')

    except KeyboardInterrupt:
        print("\n\nShutting down system safely...")
        stream.stop_stream()
        stream.close()
        audio.terminate()