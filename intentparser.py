import re
from rapidfuzz import process, fuzz

# ==========================================
# TIER 0: COMPREHENSIVE COMMAND TAXONOMY
# Synthesized from Home Automation, Time, Weather, and Reminders domains
# ==========================================
# ==========================================
# TIER 0: DEVANAGARI COMMAND TAXONOMY (EXPANDED)
# ==========================================
COMMAND_REGISTRY = {
    # Home Automation (Ghar Swachalan)
    "LIGHT_ON": [
        "‡§¨‡§§‡•ç‡§§‡•Ä ‡§ú‡§≤‡§æ‡§ì", "‡§≤‡§æ‡§á‡§ü ‡§ë‡§® ‡§ï‡§∞‡•ã", "‡§¨‡§§‡•ç‡§§‡•Ä ‡§ë‡§® ‡§ï‡§∞‡•ã", "‡§∞‡•ã‡§∂‡§®‡•Ä ‡§ï‡§∞‡•ã", 
        "‡§≤‡§æ‡§á‡§ü ‡§ö‡§æ‡§≤‡•Ç ‡§ï‡§∞‡•ã", "‡§ü‡•ç‡§Ø‡•Ç‡§¨‡§≤‡§æ‡§á‡§ü ‡§ú‡§≤‡§æ ‡§¶‡•ã", "‡§¨‡•à‡§†‡§ï ‡§ï‡•Ä ‡§≤‡§æ‡§á‡§ü ‡§ú‡§≤‡§æ‡§ì", 
        "‡§≤‡§ø‡§µ‡§ø‡§Ç‡§ó ‡§∞‡•Ç‡§Æ ‡§ï‡•Ä ‡§≤‡§æ‡§á‡§ü ‡§ë‡§® ‡§ï‡§∞‡•ã", "‡§≤‡§æ‡§á‡§ü ‡§ú‡§≤‡§æ ‡§¶‡•ã", "‡§¨‡§§‡•ç‡§§‡•Ä ‡§ö‡§æ‡§≤‡•Ç ‡§ï‡§∞‡•ã",
        "‡§¨‡§§‡•ç‡§§‡•Ä ‡§ú‡§≤‡§æ ‡§¶‡•ã", "‡§≤‡§æ‡§á‡§ü ‡§ë‡§® ‡§ï‡§∞ ‡§¶‡•ã", "‡§Ö‡§Ç‡§ß‡•á‡§∞‡§æ ‡§¶‡•Ç‡§∞ ‡§ï‡§∞‡•ã"
    ],
    "LIGHT_OFF": [
        "‡§¨‡§§‡•ç‡§§‡•Ä ‡§¨‡•Å‡§ù‡§æ‡§ì", "‡§≤‡§æ‡§á‡§ü ‡§ë‡§´ ‡§ï‡§∞‡•ã", "‡§¨‡§§‡•ç‡§§‡•Ä ‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã", "‡§Ö‡§Ç‡§ß‡•á‡§∞‡§æ ‡§ï‡§∞‡•ã", 
        "‡§≤‡§æ‡§á‡§ü ‡§¨‡§Ç‡§¶ ‡§ï‡§∞ ‡§¶‡•ã", "‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã", "‡§∏‡§¨ ‡§ë‡§´ ‡§ï‡§∞ ‡§¶‡•ã", "‡§¨‡§§‡•ç‡§§‡•Ä ‡§¨‡§Ç‡§¶ ‡§ï‡§∞ ‡§¶‡•ã",
        "‡§≤‡§æ‡§á‡§ü ‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã", "‡§¨‡§§‡•ç‡§§‡§ø‡§Ø‡§æ‡§Ç ‡§¨‡•Å‡§ù‡§æ ‡§¶‡•ã", "‡§≤‡§æ‡§á‡§ü ‡§¨‡•Å‡§ù‡§æ ‡§¶‡•ã"
    ],
    "FAN_ON": [
        "‡§™‡§Ç‡§ñ‡§æ ‡§ö‡§≤‡§æ‡§ì", "‡§´‡•à‡§® ‡§ë‡§® ‡§ï‡§∞ ‡§¶‡•ã", "‡§™‡§Ç‡§ñ‡§æ ‡§ö‡§æ‡§≤‡•Ç ‡§ï‡§∞‡•ã", "‡§™‡§Ç‡§ñ‡§æ ‡§ë‡§® ‡§ï‡§∞‡•ã", 
        "‡§´‡•à‡§® ‡§ö‡§æ‡§≤‡•Ç ‡§ï‡§∞‡•ã", "‡§™‡§Ç‡§ñ‡§æ ‡§ö‡§≤‡§æ ‡§¶‡•ã"
    ],
    "FAN_OFF": [
        "‡§™‡§Ç‡§ñ‡§æ ‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã", "‡§´‡•à‡§® ‡§ë‡§´ ‡§ï‡§∞‡•ã", "‡§™‡§Ç‡§ñ‡§æ ‡§¨‡§Ç‡§¶ ‡§ï‡§∞ ‡§¶‡•ã", "‡§´‡•à‡§® ‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã", 
        "‡§™‡§Ç‡§ñ‡§æ ‡§ë‡§´ ‡§ï‡§∞ ‡§¶‡•ã"
    ],
    "AC_ON": [
        "‡§µ‡§æ‡§§‡§æ‡§®‡•Å‡§ï‡•Ç‡§≤‡§ï ‡§ö‡§≤‡§æ‡§ì", "‡§è‡§∏‡•Ä ‡§ë‡§® ‡§ï‡§∞‡§®‡§æ", "‡§è‡§∏‡•Ä ‡§ö‡§≤‡§æ ‡§¶‡•ã", "‡§è‡§∏‡•Ä ‡§ö‡§æ‡§≤‡•Ç ‡§ï‡§∞‡•ã", 
        "‡§è‡§∏‡•Ä ‡§ë‡§® ‡§ï‡§∞‡•ã"
    ],
    
    # Time and Date (Samay aur Tarikh)
    "TIME_ASK": [
        "‡§∏‡§Æ‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à", "‡§ü‡§æ‡§á‡§Æ ‡§¨‡§§‡§æ‡§ì", "‡§ï‡§ø‡§§‡§®‡•á ‡§¨‡§ú‡•á ‡§π‡•à‡§Ç", "‡§ü‡§æ‡§á‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•Å‡§Ü", 
        "‡§ò‡§°‡§º‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ü‡§æ‡§á‡§Æ ‡§π‡•à", "‡§ü‡§æ‡§á‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à", "‡§Ö‡§≠‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡§Æ‡§Ø ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à", 
        "‡§Ö‡§≠‡•Ä ‡§ü‡§æ‡§á‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à", "‡§ï‡•ç‡§Ø‡§æ ‡§¨‡§ú‡§æ ‡§π‡•à", "‡§∏‡§Æ‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•ã", "‡§∏‡§Æ‡§ù‡•Ä"
    ],
    
    "DATE_ASK": [
        "‡§Ü‡§ú ‡§ï‡•ç‡§Ø‡§æ ‡§§‡§æ‡§∞‡•Ä‡§ñ ‡§π‡•à", "‡§Ü‡§ú ‡§ï‡•Ä ‡§°‡•á‡§ü ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à", "‡§Ü‡§ú ‡§ï‡•å‡§® ‡§∏‡•Ä ‡§§‡§æ‡§∞‡•Ä‡§ñ ‡§π‡•à",
        "‡§ï‡§≤ ‡§ï‡•ç‡§Ø‡§æ ‡§§‡§æ‡§∞‡•Ä‡§ñ ‡§π‡•ã‡§ó‡•Ä", "‡§ï‡§≤ ‡§ï‡•Ä ‡§°‡•á‡§ü ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à", "‡§Ü‡§ú ‡§ï‡§ø‡§§‡§®‡•Ä ‡§§‡§æ‡§∞‡•Ä‡§ñ ‡§π‡•à",
        "‡§Ü‡§ú ‡§ï‡•å‡§® ‡§∏‡§æ ‡§¶‡§ø‡§®‡§æ‡§Ç‡§ï ‡§π‡•à"
    ],
    "DAY_ASK": [
        "‡§Ü‡§ú ‡§ï‡•å‡§® ‡§∏‡§æ ‡§¶‡§ø‡§® ‡§π‡•à", "‡§Ü‡§ú ‡§ï‡•å‡§® ‡§∏‡§æ ‡§°‡•á ‡§π‡•à", "‡§Ü‡§ú ‡§ï‡•ç‡§Ø‡§æ ‡§¶‡§ø‡§® ‡§π‡•à", "‡§Ü‡§ú ‡§ï‡•å‡§® ‡§µ‡§æ‡§∞ ‡§π‡•à"
    ],

    # Temperature and Weather (Tapman aur Mausam)
    "WEATHER_ASK": [
        "‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•à‡§∏‡§æ ‡§π‡•à", "‡§Ü‡§ú ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•à‡§∏‡§æ ‡§π‡•à", "‡§Ü‡§ú ‡§µ‡•á‡§¶‡§∞ ‡§ï‡•à‡§∏‡§æ ‡§π‡•à", 
        "‡§Æ‡•å‡§∏‡§Æ ‡§ï‡§æ ‡§π‡§æ‡§≤ ‡§¨‡§§‡§æ‡§ì", "‡§¨‡§æ‡§π‡§∞ ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ", "‡§ï‡§≤ ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•à‡§∏‡§æ ‡§∞‡§π‡•á‡§ó‡§æ",
        "‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§ú ‡§Æ‡•å‡§∏‡§Æ ‡§∏‡§æ‡§´ ‡§π‡•à", "‡§¨‡§æ‡§π‡§∞ ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•à‡§∏‡§æ ‡§π‡•à"
    ],
    "TEMP_ASK": [
        "‡§§‡§æ‡§™‡§Æ‡§æ‡§® ‡§¨‡§§‡§æ‡§ì", "‡§¨‡§æ‡§π‡§∞ ‡§§‡§æ‡§™‡§Æ‡§æ‡§® ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à", "‡§¨‡§æ‡§π‡§∞ ‡§ï‡§ø‡§§‡§®‡§æ ‡§ü‡•á‡§Ç‡§™‡§∞‡•á‡§ö‡§∞ ‡§π‡•à", 
        "‡§ó‡§∞‡•ç‡§Æ‡•Ä ‡§ï‡§ø‡§§‡§®‡•Ä ‡§π‡•à", "‡§ï‡§Æ‡§∞‡•á ‡§ï‡§æ ‡§§‡§æ‡§™‡§Æ‡§æ‡§® ‡§¨‡§§‡§æ‡§ì", "‡§∞‡•Ç‡§Æ ‡§ü‡•á‡§Ç‡§™‡§∞‡•á‡§ö‡§∞ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à",
        "‡§Ü‡§ú ‡§ï‡§ø‡§§‡§®‡•Ä ‡§ó‡§∞‡•ç‡§Æ‡•Ä ‡§π‡•à", "‡§ü‡•á‡§Ç‡§™‡§∞‡•á‡§ö‡§∞ ‡§¨‡§§‡§æ‡§ì"
    ],
    "RAIN_ASK": [
        "‡§Ü‡§ú ‡§ï‡•Ä ‡§¨‡§æ‡§∞‡§ø‡§∂", "‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§ú ‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§π‡•ã‡§ó‡•Ä", "‡§∞‡•á‡§® ‡§ï‡•á ‡§ö‡§æ‡§Ç‡§∏‡•á‡§∏ ‡§π‡•à‡§Ç ‡§ï‡•ç‡§Ø‡§æ", 
        "‡§ï‡•ç‡§Ø‡§æ ‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§π‡•ã‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§π‡•à", "‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§π‡•ã‡§ó‡•Ä ‡§ï‡•ç‡§Ø‡§æ"
    ],

    # Reminders and Alarms (Yaad-dihani aur Alarm)
    "ALARM_SET": [
        "‡§Ö‡§≤‡§æ‡§∞‡•ç‡§Æ ‡§≤‡§ó‡§æ‡§ì", "‡§Ö‡§≤‡§æ‡§∞‡•ç‡§Æ ‡§∏‡•á‡§ü ‡§ï‡§∞‡•ã", "‡§â‡§†‡§æ ‡§¶‡•á‡§®‡§æ", "‡§Ö‡§≤‡§æ‡§∞‡•ç‡§Æ ‡§≤‡§ó‡§æ ‡§¶‡•ã", "‡§Æ‡•Å‡§ù‡•á ‡§ú‡§ó‡§æ ‡§¶‡•á‡§®‡§æ"
    ],
    "REMINDER_SET": [
        "‡§Ø‡§æ‡§¶ ‡§¶‡§ø‡§≤‡§æ‡§®‡§æ", "‡§∞‡§ø‡§Æ‡§æ‡§á‡§Ç‡§°‡§∞ ‡§∏‡•á‡§ü ‡§ï‡§∞‡•ã", "‡§Æ‡•Å‡§ù‡•á ‡§Ø‡§æ‡§¶ ‡§¶‡§ø‡§≤‡§æ‡§ì", "‡§∞‡§ø‡§Æ‡§æ‡§á‡§Ç‡§° ‡§Æ‡•Ä", "‡§∞‡§ø‡§Æ‡§æ‡§á‡§Ç‡§°‡§∞ ‡§≤‡§ó‡§æ‡§ì"
    ],
    "ALARM_STOP": [
        "‡§Ö‡§≤‡§æ‡§∞‡•ç‡§Æ ‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã", "‡§∏‡•ç‡§ü‡•â‡§™ ‡§á‡§ü", "‡§ö‡•Å‡§™ ‡§π‡•ã ‡§ú‡§æ‡§ì", "‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã", "‡§Ö‡§≤‡§æ‡§∞‡•ç‡§Æ ‡§∞‡•ã‡§ï ‡§¶‡•ã"
    ],
    
    # Translation (Anuvaad)
    "TRANSLATE_ASK": [
        "‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§π‡§§‡•á ‡§π‡•à‡§Ç", "‡§ï‡§æ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞‡•ã", "‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§≤‡•á‡§ü ‡§ï‡§∞‡•ã", 
        "‡§Æ‡§§‡§≤‡§¨ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à", "‡§Æ‡•Ä‡§®‡§ø‡§Ç‡§ó ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à", "‡§ï‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§¨‡•ã‡§≤‡§§‡•á ‡§π‡•à‡§Ç"
    ]
}

# ==========================================
# TIER 1: NORMALIZATION
# ==========================================
def normalize_text(text):
    """
    Normalize Hindi/Hinglish text: remove punctuation, extra spaces.
    Unicode range \u0900-\u097F safely covers the Devanagari script.
    """
    # Remove common punctuation, keeping alphanumeric and Devanagari
    text = re.sub(r'[^\w\s\u0900-\u097F]', '', text)
    return text.lower().strip()

# ==========================================
# TIER 2 & 3: THE WATERFALL PARSER
# ==========================================
def split_commands(text):
    """Splits a single Hindi sentence into multiple commands based on conjunctions."""
    # Split by 'aur' (‡§î‡§∞), 'tatha' (‡§§‡§•‡§æ), or 'phir' (‡§´‡§ø‡§∞)
    parts = re.split(r'\s+(‡§î‡§∞|‡§§‡§•‡§æ|‡§´‡§ø‡§∞)\s+', text)
    
    # Filter out the conjunction words themselves, keeping only the action phrases
    commands = [p.strip() for p in parts if p.strip() not in ['‡§î‡§∞', '‡§§‡§•‡§æ', '‡§´‡§ø‡§∞'] and p.strip()]
    return commands

def parse_multiple_intents(text):
    """Returns a list of intent dictionaries for a compound sentence."""
    normalized_text = normalize_text(text)
    command_phrases = split_commands(normalized_text)
    
    results = []
    for phrase in command_phrases:
        best_match = None
        highest_score = 0
        
        # Run RapidFuzz on each chopped phrase
        for intent, phrases in COMMAND_REGISTRY.items():
            match = process.extractOne(phrase, phrases, scorer=fuzz.token_set_ratio)
            if match:
                score = match[1]
                if score > highest_score:
                    highest_score = score
                    best_match = intent
                    
        if highest_score >= 85:  # 70% confidence threshold
            results.append({"intent": best_match, "confidence": round(highest_score, 2), "phrase": phrase})
        else:
            results.append({"intent": "UNKNOWN_COMMAND", "confidence": round(highest_score, 2), "phrase": phrase})
            
    return results

    # ---------------------------------------------------------
    # TIER 3: Fuzzy Matching (Handles ASR acoustic errors / typos)
    # ---------------------------------------------------------
    all_phrases = []
    phrase_to_intent = {}
    
    # Flatten the registry for the fuzzy engine
    for intent, phrases in COMMAND_REGISTRY.items():
        for p in phrases:
            all_phrases.append(p)
            phrase_to_intent[p] = intent
            
    # extractOne finds the single best match from the flattened list.
    # token_set_ratio is mathematically ideal for Hinglish as it ignores word order.
    # e.g., "karo light on" will heavily match "light on karo".
    best_match, score, _ = process.extractOne(
        clean_text, all_phrases, scorer=fuzz.token_set_ratio
    )
    
    # 80% is the recommended threshold for command-and-control voice applications
    if score > 80:
        detected_intent = phrase_to_intent[best_match]
        return {
            "intent": detected_intent, 
            "confidence": round(score, 2), 
            "match_type": "fuzzy_probabilistic",
            "matched_phrase": best_match
        }
                
    # ---------------------------------------------------------
    # TIER 4: Semantic Fallback
    # (To be routed to a quantized SLM or handled as an error)
    # ---------------------------------------------------------
    return {
        "intent": "UNKNOWN_COMMAND", 
        "confidence": 0.0, 
        "match_type": "none",
        "matched_phrase": None
    }

# ==========================================
# LOCAL TESTING BLOCK
# ==========================================
if __name__ == "__main__":
    print("üß† Tiered NLU Intent Parser Initialized.")
    print("Ready for testing. Type 'exit' to quit.\n")
    
    # Test cases demonstrating Hinglish variation, exact matches, and fuzzy matches
    test_queries = [
        "living room ki light on karo", # Exact match
        "karo light on living room ki", # Out of order (Fuzzy token_set_ratio)
        "aaj ka mosam kaisa hai",       # ASR transcription error (mosam vs mausam)
        "batti band kar do jaldi",      # Exact match with extra words
        "mujhe kal subah utha dena",    # Exact match for alarm
        "what is the meaning of life"   # Unknown command
    ]
    
    for query in test_queries:
        print(f"üó£Ô∏è Input: '{query}'")
        result = parse_multiple_intents(query)
        print(f"   ‚Ü≥ Result: {result}\n")